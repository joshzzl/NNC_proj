{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project\n",
    "#### Author: Zhili Zhang - Net ID: zz2382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import itertools\n",
    "import warnings\n",
    "from math import exp\n",
    "from model import Model\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data X\n",
    "X = [[1,1], [1,-1], [-1,1], [-1,-1]]\n",
    "\n",
    "# Input target Y\n",
    "Y = [-1,1,1,-1]\n",
    "\n",
    "X = np.array(X)\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "w01 = np.array([[-0,3378, 0.2771, 0.2859, -0.3329],\n",
    "                [0.1970, 0.3191, -0.1448, 0.3594],\n",
    "                [0.3099, 0.1904, -0.0347, -0.4861]])\n",
    "w12 = np.array([[-0.1401], [0.4919], [-0.2913], \\\n",
    "                [-0.3979], [0.3581]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(N0=2, N1=4, N2=1, x0=1.0, lr=0.2, tol=0.05, \\\n",
    "              zeta=1, epoch_thres=1000, cost='L2', transfer='tansig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We define transfer function, train, predict and mse as below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict function for classification only\n",
    "def predict(X, w1, w2, transfer=tansig):\n",
    "    transfer = np.vectorize(transfer)\n",
    "    a1 = transfer(np.dot(X,w1))\n",
    "    a1 = np.concatenate([np.array([1]*a1.shape[0]).reshape(-1,1), a1], axis=-1)\n",
    "    a2 = transfer(np.dot(a1, w2))\n",
    "    return a2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the mean squared error\n",
    "def mse(ys, T):\n",
    "    return np.sum((ys-T)**2)/ys.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X:(4,3), Y(4), w1:(3,2)[[b1,b2], [w11,w12], [w21,w22]], w2:(3,)[b,w1,w2]\n",
    "#\n",
    "def train(X, Y, w1, w2, lr, tol=0.001, transfer=tansig, d_transfer=d_tansig):\n",
    "    w1 = np.copy(w1)\n",
    "    w2 = np.copy(w2)\n",
    "    # converge flag, when delta is lower than tolerance, then converge True\n",
    "    converge = False\n",
    "    counter = 0\n",
    "    j = 0 # number of iterations\n",
    "    transfer = np.vectorize(transfer)\n",
    "    d_transfer = np.vectorize(d_tansig)\n",
    "    \n",
    "    while (not converge) and (j < 10000):\n",
    "    #while True and (j < 1000):\n",
    "        i = random.choice(4, 1)\n",
    "        #print(i)\n",
    "        a0 = X[i]\n",
    "        # n1:(2,)\n",
    "        n1 = np.dot(a0, w1).reshape(-1)\n",
    "        a1 = transfer(n1)\n",
    "        # b_a1:(3,)\n",
    "        b_a1 = np.concatenate([[1], a1], axis=0)\n",
    "        n2 = np.dot(b_a1, w2)\n",
    "        a2 = transfer(n2)\n",
    "        \n",
    "        s2 = (a2 - Y[i])*d_transfer(n2)\n",
    "        # s1i = f'(n1i)*w1i*s2\n",
    "        s1 = d_transfer(n1)*w2[1:]*s2\n",
    "        \n",
    "        # w2_ij = w2_ij - lr * a1_i * s2_j\n",
    "        # b2_j  = b2_j - lr * s2_j\n",
    "        delta_2 = b_a1 * s2\n",
    "        # w1_ij = w1_ij - lr * a0_i * s1_j\n",
    "        # b1_j  = b1_j - lr * s1_j\n",
    "        delta_1 = a0.reshape(-1,1) * s1.reshape(1,-1)\n",
    "        \n",
    "        # check if every entry in delta is below the tolerance\n",
    "        if np.all(np.absolute(delta_1) < tol) and \\\n",
    "                   np.all(np.absolute(delta_2) < tol):\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "        # the converge condition satisfied when 5 consecutive iters has\n",
    "        # delta less than tolerance\n",
    "        converge = counter >= 5\n",
    "        if not converge:\n",
    "            w2 = w2 - lr * delta_2\n",
    "            w1 = w1 - lr * delta_1\n",
    "        \n",
    "        #y_pred = predict(X, w1, w2)\n",
    "        #err = mse(y_pred, Y)\n",
    "        #if j%50==0:\n",
    "        #    print(\"Iter: {0}, err: {1:.4f}, y_pred:{2}\".format(j, err, str(y_pred)))\n",
    "        #print(delta_1, delta_2)\n",
    "        j += 1\n",
    "    '''\n",
    "    if j < 10000:\n",
    "        print(\"Iterations needed for convergence: {}\".format(j))\n",
    "    else:\n",
    "        print(\"Algorithm doesn't converge in 10000 iterations.\")\n",
    "    '''\n",
    "    return w1, w2, j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note for train method\n",
    "\n",
    "The 'converge' flag in my code is a DIY, which is set 'False' as default.\n",
    "\n",
    "I have a parameter 'tolerance' which serves as a threshold to the delta. If all entries in delta have absolute value less than tolerance, then I see the current iteration as a 'converged iteration'.\n",
    "\n",
    "Only if we have 5 consecutive 'converged iterations' are we going change the flag to True and withdraw from training while-loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with fixed learning_rate\n",
    "\n",
    "I design the experiment below. Basically I will change the learning rate and tolerance in respective experiments. For each experiment, I will perform the training for 20 times. We want to see for how many times in the experiment, the training actually has a 'good' result and even has a 'great' result.\n",
    "\n",
    "We set the standard of 'good' as $mse < 0.01$. We set the standard of 'great' as $mse < 0.001$\n",
    "\n",
    "We also present the average mse and average converging steps required for each training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.3291; y_pred: [-0.1374507  -0.96572327 -0.93708932  0.86769724]\n",
      "Iteration: 1; err: 0.0123; y_pred: [ 0.86337    -0.92668873 -0.91737658  0.8640729 ]\n",
      "Iteration: 2; err: 0.9118; y_pred: [-0.90564771 -0.95044103 -0.90190383  0.93944545]\n",
      "Iteration: 3; err: 0.9883; y_pred: [ 0.92283478 -0.91038136  0.98278757  0.91258493]\n",
      "Iteration: 4; err: 0.0162; y_pred: [ 0.87792137 -0.92524576 -0.91806773  0.80584675]\n",
      "Iteration: 5; err: 0.0083; y_pred: [ 0.91361685 -0.88984608 -0.91413077  0.92119003]\n",
      "Iteration: 6; err: 0.0128; y_pred: [ 0.85367251 -0.92217385 -0.91394946  0.8725187 ]\n",
      "Iteration: 7; err: 0.0080; y_pred: [ 0.91183518 -0.90302651 -0.91132075  0.91745892]\n",
      "Iteration: 8; err: 0.0075; y_pred: [ 0.90417823 -0.92520698 -0.93418092  0.89514346]\n",
      "Iteration: 9; err: 0.0105; y_pred: [ 0.90591277 -0.91659638 -0.92137204  0.85913092]\n",
      "Iteration: 10; err: 0.0100; y_pred: [ 0.88201224 -0.93742618 -0.9146069   0.87868409]\n",
      "Iteration: 11; err: 0.0115; y_pred: [ 0.84900325 -0.91485859 -0.91978647  0.90293734]\n",
      "Iteration: 12; err: 0.0959; y_pred: [ 0.9213691  -0.56364053 -0.57348846  0.92885262]\n",
      "Iteration: 13; err: 0.9904; y_pred: [ 0.90948354  0.98459214 -0.91028047  0.91784204]\n",
      "Iteration: 14; err: 0.0092; y_pred: [ 0.91674191 -0.91797173 -0.89614858  0.88915091]\n",
      "Iteration: 15; err: 0.0077; y_pred: [ 0.90100472 -0.93902559 -0.91513737  0.89902661]\n",
      "Iteration: 16; err: 0.4135; y_pred: [ 0.91927044 -0.81796353  0.27013168  0.96501753]\n",
      "Iteration: 17; err: 0.0178; y_pred: [ 0.91504143 -0.90173423 -0.8698178   0.8067824 ]\n",
      "Iteration: 18; err: 0.0083; y_pred: [ 0.94331711 -0.88927904 -0.89720002  0.91442413]\n",
      "Iteration: 19; err: 0.0189; y_pred: [ 0.87265478 -0.9326225  -0.92559853  0.77813479]\n",
      "lr: 2.0; tol: 0.01; Num Good: 7; Num Great: 0\n",
      "Mean Err: 0.19439745752471038; mean steps required: 278.2\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=2, tolerance=1e-2\n",
    "alpha = 2.\n",
    "tol = 1e-2\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.0025; y_pred: [ 0.9448515  -0.95357364 -0.97066529  0.93588835]\n",
      "Iteration: 1; err: 0.0015; y_pred: [ 0.97078674 -0.95648644 -0.95333756  0.96941368]\n",
      "Iteration: 2; err: 0.7554; y_pred: [ 0.76241633  0.7216027  -0.97100059  0.97685362]\n",
      "Iteration: 3; err: 0.0012; y_pred: [ 0.95829069 -0.97105067 -0.96867291  0.96235834]\n",
      "Iteration: 4; err: 0.0013; y_pred: [ 0.96908013 -0.95802075 -0.96033054  0.96950708]\n",
      "Iteration: 5; err: 0.0014; y_pred: [ 0.95972456 -0.97012544 -0.96978238  0.9544192 ]\n",
      "Iteration: 6; err: 0.0013; y_pred: [ 0.9575887  -0.97021851 -0.97049665  0.95939925]\n",
      "Iteration: 7; err: 0.0014; y_pred: [ 0.97114192 -0.95478121 -0.9582561   0.96874081]\n",
      "Iteration: 8; err: 0.0014; y_pred: [ 0.9583858  -0.96880711 -0.96916305  0.95659243]\n",
      "Iteration: 9; err: 0.0016; y_pred: [ 0.95250719 -0.97498974 -0.96889032  0.94989263]\n",
      "Iteration: 10; err: 0.0013; y_pred: [ 0.9596436  -0.96935882 -0.97020677  0.9605528 ]\n",
      "Iteration: 11; err: 0.0012; y_pred: [ 0.96182881 -0.96954609 -0.96985343  0.96121463]\n",
      "Iteration: 12; err: 0.0016; y_pred: [ 0.96929362 -0.95109    -0.95593524  0.96913469]\n",
      "Iteration: 13; err: 0.0016; y_pred: [ 0.97050778 -0.95098459 -0.95319792  0.96944175]\n",
      "Iteration: 14; err: 0.0016; y_pred: [ 0.96693197 -0.94984034 -0.95497311  0.97075755]\n",
      "Iteration: 15; err: 0.7980; y_pred: [ 0.98247473  0.77093343 -0.96385278  0.76726994]\n",
      "Iteration: 16; err: 0.0013; y_pred: [ 0.96885976 -0.9575964  -0.96079279  0.97044106]\n",
      "Iteration: 17; err: 0.0016; y_pred: [ 0.96949859 -0.95730405 -0.94822907  0.97011886]\n",
      "Iteration: 18; err: 0.0014; y_pred: [ 0.96889672 -0.95642166 -0.95797711  0.96912354]\n",
      "Iteration: 19; err: 0.0016; y_pred: [ 0.94943202 -0.96929121 -0.9692946   0.9555706 ]\n",
      "lr: 2.0; tol: 0.001; Num Good: 18; Num Great: 0\n",
      "Mean Err: 0.0790073397541759; mean steps required: 780.95\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=2, tolerance=1e-3\n",
    "alpha = 2.\n",
    "tol = 1e-3\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.0001; y_pred: [ 0.99019341 -0.98641146 -0.98669527  0.98999418]\n",
      "Iteration: 1; err: 0.0001; y_pred: [ 0.98593498 -0.99003661 -0.98970808  0.98624158]\n",
      "Iteration: 2; err: 0.0001; y_pred: [ 0.98578869 -0.99009807 -0.99019876  0.98635153]\n",
      "Iteration: 3; err: 0.0001; y_pred: [ 0.99000071 -0.98695149 -0.98587519  0.99016736]\n",
      "Iteration: 4; err: 0.0001; y_pred: [ 0.98678942 -0.99021209 -0.99008821  0.98641683]\n",
      "Iteration: 5; err: 0.0001; y_pred: [ 0.99003626 -0.98674255 -0.98575526  0.99013693]\n",
      "Iteration: 6; err: 0.0001; y_pred: [ 0.98999271 -0.98645155 -0.98693973  0.9903774 ]\n",
      "Iteration: 7; err: 0.0001; y_pred: [ 0.99004213 -0.98716335 -0.98672785  0.9902982 ]\n",
      "Iteration: 8; err: 0.0001; y_pred: [ 0.98993822 -0.98623319 -0.98653499  0.99050146]\n",
      "Iteration: 9; err: 0.0001; y_pred: [ 0.98676006 -0.98999223 -0.99006616  0.98662026]\n",
      "Iteration: 10; err: 0.0001; y_pred: [ 0.99006546 -0.98659235 -0.98622849  0.99011264]\n",
      "Iteration: 11; err: 0.0001; y_pred: [ 0.99004531 -0.98629452 -0.98594968  0.99014102]\n",
      "Iteration: 12; err: 0.0001; y_pred: [ 0.98658793 -0.9900391  -0.9905951   0.98643536]\n",
      "Iteration: 13; err: 0.0001; y_pred: [ 0.98647337 -0.99027217 -0.99008108  0.98623663]\n",
      "Iteration: 14; err: 0.0001; y_pred: [ 0.98720807 -0.99001647 -0.99056394  0.98717733]\n",
      "Iteration: 15; err: 0.0001; y_pred: [ 0.99000778 -0.98594672 -0.98586537  0.99003902]\n",
      "Iteration: 16; err: 0.0001; y_pred: [ 0.99000129 -0.98556234 -0.98615059  0.99005948]\n",
      "Iteration: 17; err: 0.0001; y_pred: [ 0.986102   -0.9898728  -0.99019585  0.98607841]\n",
      "Iteration: 18; err: 0.0001; y_pred: [ 0.99006696 -0.98618432 -0.98584544  0.99016111]\n",
      "Iteration: 19; err: 0.0001; y_pred: [ 0.98707318 -0.99002349 -0.99004905  0.9868672 ]\n",
      "lr: 2.0; tol: 0.0001; Num Good: 20; Num Great: 20\n",
      "Mean Err: 0.00014138615828503183; mean steps required: 5985.4\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=2, tolerance=1e-4\n",
    "alpha = 2.\n",
    "tol = 1e-4\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 1.0153; y_pred: [ 0.87657377 -0.92925742  0.99807689  0.77970129]\n",
      "Iteration: 1; err: 0.9730; y_pred: [ 0.96298823  0.97029592 -0.92826723  0.94094071]\n",
      "Iteration: 2; err: 0.8366; y_pred: [ 0.78456309  0.81523059 -0.93478404  0.97671959]\n",
      "Iteration: 3; err: 0.9482; y_pred: [-0.94089965 -0.87879756 -0.93346371  0.91877141]\n",
      "Iteration: 4; err: 0.0216; y_pred: [ 0.81457646 -0.79313072 -0.91917749  0.94681936]\n",
      "Iteration: 5; err: 0.9431; y_pred: [ 0.90787277  0.93699905 -0.9332033   0.91434268]\n",
      "Iteration: 6; err: 1.0024; y_pred: [ 0.95066437 -0.89909061  0.99921717  0.99826735]\n",
      "Iteration: 7; err: 1.0331; y_pred: [ 0.9594954   0.99813321 -0.62832098  0.99772421]\n",
      "Iteration: 8; err: 0.9864; y_pred: [ 0.91209788 -0.93862118 -0.93478503 -0.98239746]\n",
      "Iteration: 9; err: 0.0235; y_pred: [ 0.79851508 -0.78866203 -0.94138699  0.92629535]\n",
      "Iteration: 10; err: 0.0110; y_pred: [ 0.8691115  -0.92513347 -0.92725571  0.87303243]\n",
      "Iteration: 11; err: 0.9939; y_pred: [ 0.98645308  0.98828796 -0.87352227  0.92203337]\n",
      "Iteration: 12; err: 0.9758; y_pred: [ 0.91940183 -0.91129237  0.97050744  0.92411748]\n",
      "Iteration: 13; err: 0.0783; y_pred: [ 0.44992554 -0.99640172 -0.9944822   0.89746711]\n",
      "Iteration: 14; err: 0.0078; y_pred: [ 0.93655463 -0.87914359 -0.91379647  0.92722806]\n",
      "Iteration: 15; err: 0.8944; y_pred: [ 0.97551156  0.88704954 -0.96482359  0.87867302]\n",
      "Iteration: 16; err: 1.6821; y_pred: [0.96827002 0.98118108 0.67374913 0.97304129]\n",
      "Iteration: 17; err: 0.0079; y_pred: [ 0.88934153 -0.92861729 -0.92218834  0.91024948]\n",
      "Iteration: 18; err: 0.9976; y_pred: [ 0.99302264 -0.95962888  0.99713188  0.99368749]\n",
      "Iteration: 19; err: 0.0087; y_pred: [ 0.9506051  -0.91675812 -0.93476894  0.85452564]\n",
      "lr: 3.0; tol: 0.01; Num Good: 3; Num Great: 0\n",
      "Mean Err: 0.6720259699837114; mean steps required: 103.95\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=3, tolerance=1e-2\n",
    "alpha = 3.\n",
    "tol = 1e-2\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.0014; y_pred: [ 0.96886191 -0.95471441 -0.9584671   0.97104974]\n",
      "Iteration: 1; err: 0.9763; y_pred: [ 0.97021905 -0.96759612  0.97544055  0.97234314]\n",
      "Iteration: 2; err: 0.0012; y_pred: [ 0.95958024 -0.97694339 -0.96845082  0.96154005]\n",
      "Iteration: 3; err: 0.9680; y_pred: [ 0.97272656 -0.97183864 -0.963274   -0.96704873]\n",
      "Iteration: 4; err: 0.0021; y_pred: [ 0.94748236 -0.98131564 -0.97010404  0.93344605]\n",
      "Iteration: 5; err: 0.9742; y_pred: [ 0.98831195  0.9738565  -0.9861663   0.97684048]\n",
      "Iteration: 6; err: 0.0009; y_pred: [ 0.97250301 -0.96660776 -0.96227911  0.98313338]\n",
      "Iteration: 7; err: 0.9453; y_pred: [ 0.97358782 -0.9910548  -0.93956862 -0.9434244 ]\n",
      "Iteration: 8; err: 0.0013; y_pred: [ 0.96972564 -0.96062323 -0.95542676  0.96992545]\n",
      "Iteration: 9; err: 0.0010; y_pred: [ 0.96896918 -0.96306184 -0.96269485  0.97932203]\n",
      "Iteration: 10; err: 0.8746; y_pred: [-0.86969659 -0.97273816 -0.97933375  0.96033392]\n",
      "Iteration: 11; err: 0.0011; y_pred: [ 0.95901099 -0.97001205 -0.9770881   0.96335515]\n",
      "Iteration: 12; err: 0.0010; y_pred: [ 0.96593747 -0.97319007 -0.97204147  0.96259293]\n",
      "Iteration: 13; err: 0.0013; y_pred: [ 0.9717936  -0.95937742 -0.95720148  0.97063195]\n",
      "Iteration: 14; err: 1.0869; y_pred: [ 0.97240064 -0.390302   -0.99280368 -0.9938015 ]\n",
      "Iteration: 15; err: 0.0012; y_pred: [ 0.95423178 -0.98022736 -0.96888867  0.96191714]\n",
      "Iteration: 16; err: 0.0014; y_pred: [ 0.96988552 -0.95411162 -0.95951821  0.97105894]\n",
      "Iteration: 17; err: 0.0323; y_pred: [ 0.98566346 -0.98194184 -0.64143925  0.98596518]\n",
      "Iteration: 18; err: 0.0124; y_pred: [ 0.84150252 -0.93249266 -0.97281031  0.86115677]\n",
      "Iteration: 19; err: 0.0008; y_pred: [ 0.98441968 -0.9677533  -0.96698167  0.97372881]\n",
      "lr: 3.0; tol: 0.001; Num Good: 12; Num Great: 2\n",
      "Mean Err: 0.2942458002200694; mean steps required: 442.9\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=3, tolerance=1e-3\n",
    "alpha = 3.\n",
    "tol = 1e-3\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.0001; y_pred: [ 0.98999788 -0.98654805 -0.98605265  0.99004494]\n",
      "Iteration: 1; err: 0.0001; y_pred: [ 0.98974162 -0.98601573 -0.98593038  0.99027955]\n",
      "Iteration: 2; err: 0.9726; y_pred: [ 0.99410718 -0.97191025 -0.9964371  -0.9721612 ]\n",
      "Iteration: 3; err: 0.0001; y_pred: [ 0.99011229 -0.98596172 -0.98644466  0.99011865]\n",
      "Iteration: 4; err: 0.0067; y_pred: [ 0.99377797 -0.86060232 -0.91375287  0.99169962]\n",
      "Iteration: 5; err: 0.9749; y_pred: [ 0.99625311  0.97459954 -0.99535088  0.97435663]\n",
      "Iteration: 6; err: 0.0001; y_pred: [ 0.9864801  -0.99002947 -0.99112344  0.98707674]\n",
      "Iteration: 7; err: 0.0002; y_pred: [ 0.9852887  -0.99041169 -0.98956369  0.98641208]\n",
      "Iteration: 8; err: 0.0001; y_pred: [ 0.98680042 -0.99029433 -0.99007515  0.98708193]\n",
      "Iteration: 9; err: 0.0002; y_pred: [ 0.98554899 -0.99001205 -0.98936071  0.98523786]\n",
      "Iteration: 10; err: 0.0001; y_pred: [ 0.98615136 -0.99040545 -0.99003612  0.98673443]\n",
      "Iteration: 11; err: 0.0017; y_pred: [ 0.93437671 -0.9930943  -0.99375568  0.94935923]\n",
      "Iteration: 12; err: 0.0001; y_pred: [ 0.98688084 -0.99112725 -0.98943172  0.98610631]\n",
      "Iteration: 13; err: 0.0001; y_pred: [ 0.98656474 -0.99001306 -0.99001917  0.98723875]\n",
      "Iteration: 14; err: 0.0003; y_pred: [ 0.99115423 -0.97934057 -0.97737566  0.98115127]\n",
      "Iteration: 15; err: 0.0001; y_pred: [ 0.98663566 -0.99063753 -0.99001916  0.98669795]\n",
      "Iteration: 16; err: 0.0336; y_pred: [ 0.99333687 -0.68855449 -0.8071111   0.99306311]\n",
      "Iteration: 17; err: 0.0001; y_pred: [ 0.99031644 -0.9869872  -0.98649947  0.9901946 ]\n",
      "Iteration: 18; err: 0.0002; y_pred: [ 0.98872414 -0.98432512 -0.98538193  0.99015778]\n",
      "Iteration: 19; err: 0.0001; y_pred: [ 0.99028621 -0.98615314 -0.9860002   0.99003114]\n",
      "lr: 3.0; tol: 0.0001; Num Good: 17; Num Great: 15\n",
      "Mean Err: 0.0995956441637316; mean steps required: 3152.0\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=3, tolerance=1e-4\n",
    "alpha = 3.\n",
    "tol = 1e-4\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out the experiment results\n",
    "lr: 2.0; tol: 0.01; Num Good: 7; Num Great: 0; Mean err: 0.194; average converge steps: 278\n",
    "\n",
    "lr: 2.0; tol: 0.001; Num Good: 18; Num Great: 0; Mean err: 0.079; average converge steps: 781\n",
    "\n",
    "lr: 2.0; tol: 0.0001; Num Good: 20; Num Great: 20; Mean err: 1.4e-4; average converge steps: 5985\n",
    "\n",
    "lr: 3.0; tol: 0.01; Num Good: 3; Num Great: 0; Mean err: 0.672; average converge steps: 104\n",
    "\n",
    "lr: 3.0; tol: 0.001; Num Good: 12; Num Great: 2; Mean err: 0.294; average converge steps: 443\n",
    "\n",
    "lr: 3.0; tol: 0.0001; Num Good: 17; Num Great: 15; Mean err: 0.099; average converge steps: 3152\n",
    "\n",
    "When lr is fixed, 2 patterns are found:\n",
    "\n",
    "- When learning rate is lower, there are relatively more good and great results, and lower mean err.\n",
    "- When tolerance is lower, there are more good and great results, and lower mean err\n",
    "- When learning rate or tolerance is low, it took more steps to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments with adaptive learning rate\n",
    "\n",
    "I also apply adaptive learning rate in following codes.\n",
    "During each iteration of training, we calculate the prediciton results and mean squared error. Then we set the learning rate as:\n",
    "$$ lr = base\\_lr * (1+mse) $$\n",
    "$base\\_lr$ is the preset lr as parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X:(4,3), Y(4), w1:(3,2)[[b1,b2], [w11,w12], [w21,w22]], w2:(3,)[b,w1,w2]\n",
    "#\n",
    "def adaptive_train(X, Y, w1, w2, base_lr, tol=0.001, transfer=tansig, d_transfer=d_tansig):\n",
    "    w1 = np.copy(w1)\n",
    "    w2 = np.copy(w2)\n",
    "    # converge flag, when delta is lower than tolerance, then converge True\n",
    "    converge = False\n",
    "    counter = 0\n",
    "    j = 0 # number of iterations\n",
    "    transfer = np.vectorize(transfer)\n",
    "    d_transfer = np.vectorize(d_tansig)\n",
    "    \n",
    "    lr = base_lr\n",
    "    \n",
    "    while (not converge) and (j < 10000):\n",
    "    #while True and (j < 1000):\n",
    "        i = random.choice(4, 1)\n",
    "        #print(i)\n",
    "        a0 = X[i]\n",
    "        # n1:(2,)\n",
    "        n1 = np.dot(a0, w1).reshape(-1)\n",
    "        a1 = transfer(n1)\n",
    "        # b_a1:(3,)\n",
    "        b_a1 = np.concatenate([[1], a1], axis=0)\n",
    "        n2 = np.dot(b_a1, w2)\n",
    "        a2 = transfer(n2)\n",
    "        \n",
    "        s2 = (a2 - Y[i])*d_transfer(n2)\n",
    "        # s1i = f'(n1i)*w1i*s2\n",
    "        s1 = d_transfer(n1)*w2[1:]*s2\n",
    "        \n",
    "        # w2_ij = w2_ij - lr * a1_i * s2_j\n",
    "        # b2_j  = b2_j - lr * s2_j\n",
    "        delta_2 = b_a1 * s2\n",
    "        # w1_ij = w1_ij - lr * a0_i * s1_j\n",
    "        # b1_j  = b1_j - lr * s1_j\n",
    "        delta_1 = a0.reshape(-1,1) * s1.reshape(1,-1)\n",
    "        \n",
    "        # check if every entry in delta is below the tolerance\n",
    "        if np.all(np.absolute(delta_1) < tol) and \\\n",
    "                   np.all(np.absolute(delta_2) < tol):\n",
    "            counter += 1\n",
    "        else:\n",
    "            counter = 0\n",
    "        # the converge condition satisfied when 5 consecutive iters has\n",
    "        # delta less than tolerance\n",
    "        converge = counter >= 5\n",
    "        if not converge:\n",
    "            w2 = w2 - lr * delta_2\n",
    "            w1 = w1 - lr * delta_1\n",
    "        \n",
    "        err = mse(predict(X, w1, w2), Y)\n",
    "        lr = base_lr * (1+err)\n",
    "        j += 1\n",
    "\n",
    "    return w1, w2, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.9989; y_pred: [ 0.99473446  0.99838327 -0.9985442   0.95555841]\n",
      "Iteration: 1; err: 1.9994; y_pred: [-0.99975738 -0.99974845 -0.99971013 -0.99968146]\n",
      "Iteration: 2; err: 1.9595; y_pred: [-0.99885923 -0.99905756  0.96019714  0.98832522]\n",
      "Iteration: 3; err: 0.0016; y_pred: [ 0.95575232 -0.96488795 -0.96968995  0.95418295]\n",
      "Iteration: 4; err: 1.0146; y_pred: [ 0.75453181 -0.99846294 -0.99989765 -0.99956641]\n",
      "Iteration: 5; err: 1.9340; y_pred: [-0.99953257 -0.9841586  -0.9736421  -0.93315715]\n",
      "Iteration: 6; err: 1.9990; y_pred: [-0.99971533 -0.99983636  0.99933363  0.9993021 ]\n",
      "Iteration: 7; err: 0.0023; y_pred: [ 0.97654888 -0.92801187 -0.94513351  0.98350704]\n",
      "Iteration: 8; err: 1.0029; y_pred: [ 0.99848814 -0.91882028  0.99999768  0.92877074]\n",
      "Iteration: 9; err: 1.0007; y_pred: [ 0.99892939 -0.9450138   0.99996598  0.99992143]\n",
      "Iteration: 10; err: 1.9952; y_pred: [ 0.99954698 -0.9954428   0.99954101 -0.9956703 ]\n",
      "Iteration: 11; err: 1.9726; y_pred: [-0.99686694  0.97559572 -0.99048861  0.99366457]\n",
      "Iteration: 12; err: 1.9911; y_pred: [0.9912183  0.9961251  0.99497052 0.99617092]\n",
      "Iteration: 13; err: 0.9905; y_pred: [ 0.94681132  0.98956289 -0.97221129  0.99889885]\n",
      "Iteration: 14; err: 0.0011; y_pred: [ 0.9623485  -0.97148    -0.97280835  0.96164491]\n",
      "Iteration: 15; err: 1.0036; y_pred: [ 0.92499205 -0.90532656 -0.99738976 -0.99994809]\n",
      "Iteration: 16; err: 1.9994; y_pred: [-0.99951415 -0.99953902  0.99984198  0.99962338]\n",
      "Iteration: 17; err: 0.0012; y_pred: [ 0.9594537  -0.96950993 -0.96927114  0.96437019]\n",
      "Iteration: 18; err: 1.0017; y_pred: [-0.99987453 -0.96171396 -0.92450057  0.99674353]\n",
      "Iteration: 19; err: 0.5465; y_pred: [-0.18187865 -0.11191835 -0.99982752  0.98045879]\n",
      "lr: 2.0; tol: 0.001; Num Good: 4; Num Great: 0\n",
      "Mean Err: 1.1707935003874632; mean steps required: 196.35\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=2, tolerance=1e-3\n",
    "alpha = 2.\n",
    "tol = 1e-3\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = adaptive_train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 1.7378; y_pred: [-0.99996845 -0.99601393 -0.99987655 -0.71792245]\n",
      "Iteration: 1; err: 0.9846; y_pred: [ 0.98433732 -0.99668392  0.98445889  0.99739495]\n",
      "Iteration: 2; err: 1.0001; y_pred: [ 0.98658673 -0.98612653 -0.99242339 -0.99999662]\n",
      "Iteration: 3; err: 0.9788; y_pred: [ 0.97799152  0.97854059 -0.99396111  0.99402679]\n",
      "Iteration: 4; err: 1.9969; y_pred: [ 0.99991432 -0.99867731  0.99986002 -0.99699795]\n",
      "Iteration: 5; err: 1.0072; y_pred: [ 0.91082214  0.99996675 -0.85481633  0.99085549]\n",
      "Iteration: 6; err: 1.0002; y_pred: [ 0.98227868 -0.98245245 -0.98260131 -0.99999847]\n",
      "Iteration: 7; err: 0.9959; y_pred: [ 0.99163339  0.99582627 -0.99205645  0.9993632 ]\n",
      "Iteration: 8; err: 1.0009; y_pred: [ 0.96597666 -0.9999057  -0.94787398 -0.99995306]\n",
      "Iteration: 9; err: 1.0014; y_pred: [ 0.95138046 -0.9535952   0.99997479  0.96453833]\n",
      "Iteration: 10; err: 0.9196; y_pred: [ 0.99096158 -0.91583664 -0.99848063 -0.91603073]\n",
      "Iteration: 11; err: 0.0001; y_pred: [ 0.98656036 -0.99030333 -0.99000125  0.98623833]\n",
      "Iteration: 12; err: 1.9983; y_pred: [ 0.99946205  0.99910853 -0.99908524 -0.99923931]\n",
      "Iteration: 13; err: 1.0002; y_pred: [-0.99999157 -0.98777524 -0.98410392  0.98033886]\n",
      "Iteration: 14; err: 1.0006; y_pred: [ 0.97108663 -0.97287884 -0.97232889 -0.99999014]\n",
      "Iteration: 15; err: 1.0024; y_pred: [ 0.93302986 -0.9988863   0.99999927  0.92843006]\n",
      "Iteration: 16; err: 1.0003; y_pred: [ 0.98043594 -0.99995166 -0.97044243 -0.99995166]\n",
      "Iteration: 17; err: 1.0001; y_pred: [-0.99998616 -0.98636258 -0.99363034  0.98624481]\n",
      "Iteration: 18; err: 0.9647; y_pred: [ 0.99370807  0.96400018 -0.99396135  0.96354159]\n",
      "Iteration: 19; err: 0.0001; y_pred: [ 0.98677555 -0.99021866 -0.99004961  0.98636002]\n",
      "lr: 2.0; tol: 0.0001; Num Good: 2; Num Great: 2\n",
      "Mean Err: 1.029511016229861; mean steps required: 1438.65\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=2, tolerance=1e-4\n",
    "alpha = 2.\n",
    "tol = 1e-4\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = adaptive_train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0; err: 0.0002; y_pred: [ 0.99012159 -0.98580541 -0.98571111  0.98944793]\n",
      "Iteration: 1; err: 0.0001; y_pred: [ 0.99025572 -0.98677886 -0.98651359  0.98982934]\n",
      "Iteration: 2; err: 0.9318; y_pred: [ 0.96246551 -0.99291873 -0.9280235  -0.92887984]\n",
      "Iteration: 3; err: 0.0001; y_pred: [ 0.99046972 -0.9864826  -0.98636748  0.98999222]\n",
      "Iteration: 4; err: 0.0001; y_pred: [ 0.99014596 -0.98644564 -0.98666977  0.99005014]\n",
      "Iteration: 5; err: 0.0001; y_pred: [ 0.98646235 -0.99036706 -0.98999664  0.98654901]\n",
      "Iteration: 6; err: 0.0001; y_pred: [ 0.99005196 -0.98610562 -0.98616744  0.98997421]\n",
      "Iteration: 7; err: 0.0001; y_pred: [ 0.99031502 -0.98654654 -0.98566914  0.99001908]\n",
      "Iteration: 8; err: 0.0001; y_pred: [ 0.99003423 -0.98658251 -0.98678217  0.99008007]\n",
      "Iteration: 9; err: 0.5094; y_pred: [ 0.9922989  -0.99123164  0.13254636  0.13122135]\n",
      "Iteration: 10; err: 0.0001; y_pred: [ 0.98617222 -0.99008322 -0.99067254  0.98682075]\n",
      "Iteration: 11; err: 0.0001; y_pred: [ 0.99061155 -0.98596507 -0.98620903  0.98989007]\n",
      "Iteration: 12; err: 0.0001; y_pred: [ 0.98589621 -0.99007656 -0.99008297  0.9865619 ]\n",
      "Iteration: 13; err: 0.0002; y_pred: [ 0.98827069 -0.98474243 -0.98426843  0.99003172]\n",
      "Iteration: 14; err: 0.0003; y_pred: [ 0.98669953 -0.97977461 -0.98013024  0.98434565]\n",
      "Iteration: 15; err: 0.0002; y_pred: [ 0.99020621 -0.98514595 -0.98533234  0.98872224]\n",
      "Iteration: 16; err: 0.9355; y_pred: [ 0.99088999 -0.99200352 -0.93239684 -0.93323318]\n",
      "Iteration: 17; err: 1.0002; y_pred: [-0.99997162 -0.97762952 -0.9896128   0.97838937]\n",
      "Iteration: 18; err: 1.0016; y_pred: [ 0.93486929 -0.94951584 -0.999879   -0.999889  ]\n",
      "Iteration: 19; err: 0.6084; y_pred: [ 0.9921799  -0.99352291 -0.46464746 -0.46527482]\n",
      "lr: 1.5; tol: 0.0001; Num Good: 14; Num Great: 14\n",
      "Mean Err: 0.24946010831743815; mean steps required: 5976.45\n"
     ]
    }
   ],
   "source": [
    "# here we set alpha=1, tolerance=1e-4\n",
    "alpha = 1.5\n",
    "tol = 1e-4\n",
    "w1 = np.random.rand(3,2) - 0.5\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "\n",
    "good = 0\n",
    "great = 0\n",
    "steps = []\n",
    "errs = []\n",
    "for i in range(20):\n",
    "    tw1, tw2, step = adaptive_train(X, Y, w1, w2, alpha, tol=tol)\n",
    "    y_pred = predict(X, tw1, tw2)\n",
    "    err = mse(y_pred, Y)\n",
    "    steps.append(step)\n",
    "    errs.append(err)\n",
    "    if err < 1e-2:\n",
    "        good += 1\n",
    "        if err < 1e-3:\n",
    "            great += 1\n",
    "    print(\"Iteration: {0}; err: {1:.4f}; y_pred: {2}\".\\\n",
    "          format(i, err, str(y_pred)))\n",
    "print(\"lr: {}; tol: {}; Num Good: {}; Num Great: {}\".format(alpha, str(tol), good, great))\n",
    "print(\"Mean Err: {}; mean steps required: {}\".format(np.mean(errs), np.mean(steps)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort out the experiment results\n",
    "lr: 2.0; tol: 0.001; Num Good: 4; Num Great: 0; Mean err: 1.17; average converge steps: 196\n",
    "\n",
    "lr: 2.0; tol: 0.0001; Num Good: 2; Num Great: 2; Mean err: 1.03; average converge steps: 1439\n",
    "\n",
    "lr: 1.5; tol: 0.0001; Num Good: 14; Num Great: 14; Mean err: 0.25; average converge steps: 5976\n",
    "\n",
    "\n",
    "Compared with fixed learning rate:\n",
    "\n",
    "- Adaptive learning rate results in faster convergence.\n",
    "- The results are more unstable. There are more 'bad' convergence and as a result bad prediction.\n",
    "- The corresponding mean err also larger than counterpart in fixed lr experiments."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
